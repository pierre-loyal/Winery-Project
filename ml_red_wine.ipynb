{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib as plt \n",
    "import seaborn as sns \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_wine_with_dup= pd.read_csv('winequality-red.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1599, 12)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red_wine_with_dup.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "240"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red_wine_with_dup.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_wine= red_wine_with_dup.drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1359, 12)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red_wine.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding label column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_wine ['quality_label'] = red_wine['quality'].apply(\n",
    "lambda value: 'low'\n",
    "    if value <= 5 \n",
    "    else 'medium' if value <= 7 \n",
    "    else 'high')\n",
    "\n",
    "red_wine['quality_label'] = pd.Categorical(red_wine['quality_label'],\n",
    "categories=['low', 'medium', 'high'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label counts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low quality count: 640\n",
      "Medium quality count: 702\n",
      "High quality count: 17\n"
     ]
    }
   ],
   "source": [
    "# Getting the counts of each label\n",
    "counts = red_wine['quality_label'].value_counts()\n",
    "\n",
    "# Accessing each count individually\n",
    "low_count = counts.get('low', 0)  # Gets the count for 'low', defaults to 0 if 'low' is not found\n",
    "medium_count = counts.get('medium', 0)  # Gets the count for 'medium', defaults to 0 if 'medium' is not found\n",
    "high_count = counts.get('high', 0)  # Gets the count for 'high', defaults to 0 if 'high' is not found\n",
    "\n",
    "# Printing the counts\n",
    "print(f\"Low quality count: {low_count}\")\n",
    "print(f\"Medium quality count: {medium_count}\")\n",
    "print(f\"High quality count: {high_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Wine Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#red_wine['wine_type'] = 'Red'\n",
    "#white_wine['wine_type'] = 'White'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding Label Encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "red_wine['quality_label'] = label_encoder.fit_transform(red_wine['quality_label'])\n",
    "\n",
    "# Unique species after label encoding\n",
    "print(red_wine['quality_label'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'high': 0, 'low': 1, 'medium': 2}\n"
     ]
    }
   ],
   "source": [
    "class_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "\n",
    "print(class_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>quality_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.075</td>\n",
       "      <td>13.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.66         0.00             1.8      0.075   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 13.0                  40.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  quality_label  \n",
       "0      9.4        5              1  \n",
       "1      9.8        5              1  \n",
       "2      9.8        5              1  \n",
       "3      9.8        6              2  \n",
       "4      9.4        5              1  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red_wine.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split    \n",
    "\n",
    "# Split data into features (X) and target (y)\n",
    "# Ensure 'quality_label' is not included in the encoded columns if it's your target variable\n",
    "X = red_wine.drop(['quality_label','quality'] , axis = 1)\n",
    "y = red_wine['quality_label']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=52)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression with outliners "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6911764705882353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pierreloyal/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Initialize and fit the logistic regression model\n",
    "lr_model_red = LogisticRegression(random_state=42)\n",
    "\n",
    "#fit model\n",
    "lr_model_red.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "pred=lr_model_red.predict(X_test)\n",
    "\n",
    "# import accuracy_score  metric\n",
    "from sklearn.metrics import  accuracy_score \n",
    "\n",
    "# Calculate and print the accuracy score\n",
    "acc = accuracy_score(y_test, pred)\n",
    "\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest with outliners "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7279411764705882\n"
     ]
    }
   ],
   "source": [
    "# import Random Forest Classifier model\n",
    "from  sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Building model \n",
    "rf_model_red =  RandomForestClassifier(n_estimators = 100, criterion = 'entropy', random_state=453)\n",
    "\n",
    "# fit model \n",
    "rf_model_red.fit(X_train, y_train)\n",
    "\n",
    "# Predict \n",
    "y_pred = rf_model_red.predict(X_test)\n",
    "\n",
    "# Evaluate \n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  4],\n",
       "       [ 0, 93, 36],\n",
       "       [ 0, 44, 95]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.6815594039724568\n",
      "Recall: 0.6911764705882353\n",
      "F1-Score: 0.6859921648259766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pierreloyal/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# Calculate precision, recall, and F1-score\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_test, pred, average='weighted')\n",
    "\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1-Score: {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IQR - Outliners "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset size: 1359\n",
      "Filtered dataset size: 1347\n",
      "Number of outliers removed: 12\n"
     ]
    }
   ],
   "source": [
    "# Calculate Q1, Q3, and IQR \n",
    "\n",
    "Q1 = red_wine['alcohol'].quantile(0.25)\n",
    "Q3 = red_wine['alcohol'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define thresholds for outliers\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "#identify outliers\n",
    "outliers = red_wine[(red_wine['alcohol'] < lower_bound) | (red_wine['alcohol'] > upper_bound)]\n",
    "\n",
    "# Remove\n",
    "red_wine_filtered = red_wine[(red_wine['alcohol'] >= lower_bound) & (red_wine['alcohol'] <= upper_bound)]\n",
    "\n",
    "print(f\"Original dataset size: {len(red_wine)}\")\n",
    "print(f\"Filtered dataset size: {len(red_wine_filtered)}\")\n",
    "print(f\"Number of outliers removed: {len(outliers)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Logistic Regression without outliners (red_wine_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6777777777777778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pierreloyal/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split    \n",
    "\n",
    "# Split data into features (X) and target (y)\n",
    "# Ensure 'quality_label' is not included in the encoded columns if it's your target variable\n",
    "X = red_wine_filtered.drop(['quality_label','quality'] , axis = 1)\n",
    "y = red_wine_filtered['quality_label']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=52)\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Initialize and fit the logistic regression model\n",
    "lr_model_red_filtered = LogisticRegression(random_state=42)\n",
    "\n",
    "#fit model\n",
    "lr_model_red_filtered.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "pred=lr_model_red_filtered.predict(X_test)\n",
    "\n",
    "# import accuracy_score  metric\n",
    "from sklearn.metrics import  accuracy_score \n",
    "\n",
    "# Calculate and print the accuracy score\n",
    "acc = accuracy_score(y_test, pred)\n",
    "\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Random forrest without outliners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7111111111111111\n"
     ]
    }
   ],
   "source": [
    "# import Random Forest Classifier model\n",
    "from  sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Building model \n",
    "rf_model_red_filtered =  RandomForestClassifier(n_estimators = 100, criterion = 'entropy', random_state=453)\n",
    "\n",
    "# fit model \n",
    "rf_model_red_filtered.fit(X_train, y_train)\n",
    "\n",
    "# Predict \n",
    "y_pred = rf_model_red_filtered.predict(X_test)\n",
    "\n",
    "# Evaluate \n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  1],\n",
       "       [ 0, 84, 37],\n",
       "       [ 0, 49, 99]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.63      0.69      0.66       121\n",
      "           2       0.72      0.67      0.69       148\n",
      "\n",
      "    accuracy                           0.68       270\n",
      "   macro avg       0.45      0.45      0.45       270\n",
      "weighted avg       0.68      0.68      0.68       270\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pierreloyal/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/pierreloyal/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/pierreloyal/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, pred))\n",
    "\n",
    "#{'high': 0, 'low': 1, 'medium': 2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision, Recall, and F1-Score Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.6791479916335852\n",
      "Recall: 0.6777777777777778\n",
      "F1-Score: 0.6772316618317447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pierreloyal/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# Calculate precision, recall, and F1-score\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_test, pred, average='weighted')\n",
    "\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1-Score: {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stratified Kfold with Accuracy per folder and average accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Ratio: 1.504047093451067\n"
     ]
    }
   ],
   "source": [
    "print('Class Ratio:',sum(red_wine['quality_label'])/len(red_wine['quality_label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Accuracy: 0.7426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pierreloyal/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/pierreloyal/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 Accuracy: 0.7316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pierreloyal/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 Accuracy: 0.7169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pierreloyal/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 Accuracy: 0.7243\n",
      "Fold 5 Accuracy: 0.7269\n",
      "\n",
      "Average Accuracy: 0.7285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pierreloyal/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "\n",
    "# Assuming 'red_wine' is your DataFrame and 'quality_label' is the column for stratification\n",
    "target = red_wine['quality_label']\n",
    "\n",
    "# Initialize StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Store accuracies for later averaging\n",
    "accuracies = []\n",
    "\n",
    "# Enumerate over folds, starting from 1\n",
    "for fold_no, (train_index, test_index) in enumerate(skf.split(red_wine, target), start=1):\n",
    "    # Create training and testing sets\n",
    "    X_train = red_wine.iloc[train_index].drop(['quality_label', 'quality'], axis=1)\n",
    "    y_train = red_wine.iloc[train_index]['quality_label']\n",
    "    X_test = red_wine.iloc[test_index].drop(['quality_label', 'quality'], axis=1)\n",
    "    y_test = red_wine.iloc[test_index]['quality_label']\n",
    "    \n",
    "    # Initialize and train the logistic regression model\n",
    "    lr_model_red = LogisticRegression(max_iter=1000)\n",
    "    lr_model_red.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict and calculate accuracy\n",
    "    pred = lr_model_red.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    accuracies.append(accuracy)\n",
    "    \n",
    "    # Print accuracy for the current fold\n",
    "    print(f'Fold {fold_no} Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Print average accuracy after all folds\n",
    "average_accuracy = sum(accuracies) / len(accuracies)\n",
    "print(f'\\nAverage Accuracy: {average_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balanced accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pierreloyal/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Balanced Accuracy: 0.5013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pierreloyal/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 Balanced Accuracy: 0.4952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pierreloyal/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 Balanced Accuracy: 0.4862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pierreloyal/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 Balanced Accuracy: 0.4891\n",
      "Fold 5 Balanced Accuracy: 0.4896\n",
      "\n",
      "Average Balanced Accuracy: 0.4923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pierreloyal/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "\n",
    "# Assuming 'red_wine' is your DataFrame and 'quality_label' is the column for stratification\n",
    "target = red_wine['quality_label']\n",
    "\n",
    "# Initialize StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Store balanced accuracies for later averaging\n",
    "balanced_accuracies = []\n",
    "\n",
    "# Enumerate over folds, starting from 1\n",
    "for fold_no, (train_index, test_index) in enumerate(skf.split(red_wine, target), start=1):\n",
    "    # Create training and testing sets\n",
    "    X_train = red_wine.iloc[train_index].drop(['quality_label', 'quality'], axis=1)\n",
    "    y_train = red_wine.iloc[train_index]['quality_label']\n",
    "    X_test = red_wine.iloc[test_index].drop(['quality_label', 'quality'], axis=1)\n",
    "    y_test = red_wine.iloc[test_index]['quality_label']\n",
    "    \n",
    "    # Initialize and train the logistic regression model\n",
    "    lr_model = LogisticRegression(max_iter=1000)\n",
    "    lr_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict and calculate balanced accuracy\n",
    "    pred = lr_model.predict(X_test)\n",
    "    balanced_accuracy = balanced_accuracy_score(y_test, pred)\n",
    "    balanced_accuracies.append(balanced_accuracy)\n",
    "    \n",
    "    # Print balanced accuracy for the current fold\n",
    "    print(f'Fold {fold_no} Balanced Accuracy: {balanced_accuracy:.4f}')\n",
    "\n",
    "# Print average balanced accuracy after all folds\n",
    "average_balanced_accuracy = sum(balanced_accuracies) / len(balanced_accuracies)\n",
    "print(f'\\nAverage Balanced Accuracy: {average_balanced_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balanced accuracy with Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Balanced Accuracy: 0.5186\n",
      "Fold 2 Balanced Accuracy: 0.5039\n",
      "Fold 3 Balanced Accuracy: 0.4705\n",
      "Fold 4 Balanced Accuracy: 0.5082\n",
      "Fold 5 Balanced Accuracy: 0.5182\n",
      "\n",
      "Average Balanced Accuracy: 0.5039\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from  sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "\n",
    "# Assuming 'red_wine' is your DataFrame and 'quality_label' is the column for stratification\n",
    "target = red_wine['quality_label']\n",
    "\n",
    "# Initialize StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Store balanced accuracies for later averaging\n",
    "balanced_accuracies = []\n",
    "\n",
    "# Enumerate over folds, starting from 1\n",
    "for fold_no, (train_index, test_index) in enumerate(skf.split(red_wine, target), start=1):\n",
    "    # Create training and testing sets\n",
    "    X_train = red_wine.iloc[train_index].drop(['quality_label', 'quality'], axis=1)\n",
    "    y_train = red_wine.iloc[train_index]['quality_label']\n",
    "    X_test = red_wine.iloc[test_index].drop(['quality_label', 'quality'], axis=1)\n",
    "    y_test = red_wine.iloc[test_index]['quality_label']\n",
    "    \n",
    "    # Initialize and train the logistic regression model\n",
    "    rf_model = RandomForestClassifier(n_estimators = 100, criterion = 'entropy', random_state=453)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict and calculate balanced accuracy\n",
    "    pred = rf_model.predict(X_test)\n",
    "    balanced_accuracy = balanced_accuracy_score(y_test, pred)\n",
    "    balanced_accuracies.append(balanced_accuracy)\n",
    "    \n",
    "    # Print balanced accuracy for the current fold\n",
    "    print(f'Fold {fold_no} Balanced Accuracy: {balanced_accuracy:.4f}')\n",
    "\n",
    "# Print average balanced accuracy after all folds\n",
    "average_balanced_accuracy = sum(balanced_accuracies) / len(balanced_accuracies)\n",
    "print(f'\\nAverage Balanced Accuracy: {average_balanced_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balanced accuracy with Gradient Boosting Machines "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Balanced Accuracy: 0.4985\n",
      "Fold 2 Balanced Accuracy: 0.4689\n",
      "Fold 3 Balanced Accuracy: 0.4879\n",
      "Fold 4 Balanced Accuracy: 0.4911\n",
      "Fold 5 Balanced Accuracy: 0.5115\n",
      "\n",
      "Average Balanced Accuracy: 0.4916\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from  sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "\n",
    "# Assuming 'red_wine' is your DataFrame and 'quality_label' is the column for stratification\n",
    "target = red_wine['quality_label']\n",
    "\n",
    "# Initialize StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Store balanced accuracies for later averaging\n",
    "balanced_accuracies = []\n",
    "\n",
    "# Enumerate over folds, starting from 1\n",
    "for fold_no, (train_index, test_index) in enumerate(skf.split(red_wine, target), start=1):\n",
    "    # Create training and testing sets\n",
    "    X_train = red_wine.iloc[train_index].drop(['quality_label', 'quality'], axis=1)\n",
    "    y_train = red_wine.iloc[train_index]['quality_label']\n",
    "    X_test = red_wine.iloc[test_index].drop(['quality_label', 'quality'], axis=1)\n",
    "    y_test = red_wine.iloc[test_index]['quality_label']\n",
    "    \n",
    "    # Initialize and train the logistic regression model\n",
    "    gbm_model = GradientBoostingClassifier(n_estimators=100, random_state=453)\n",
    "    gbm_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict and calculate balanced accuracy\n",
    "    pred = gbm_model.predict(X_test)\n",
    "    balanced_accuracy = balanced_accuracy_score(y_test, pred)\n",
    "    balanced_accuracies.append(balanced_accuracy)\n",
    "    \n",
    "    # Print balanced accuracy for the current fold\n",
    "    print(f'Fold {fold_no} Balanced Accuracy: {balanced_accuracy:.4f}')\n",
    "\n",
    "# Print average balanced accuracy after all folds\n",
    "average_balanced_accuracy = sum(balanced_accuracies) / len(balanced_accuracies)\n",
    "print(f'\\nAverage Balanced Accuracy: {average_balanced_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        high       0.00      0.00      0.00         3\n",
      "         low       0.78      0.73      0.76       128\n",
      "      medium       0.75      0.80      0.78       140\n",
      "\n",
      "    accuracy                           0.76       271\n",
      "   macro avg       0.51      0.51      0.51       271\n",
      "weighted avg       0.76      0.76      0.76       271\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pred, target_names=[\"high\",\"low\",\"medium\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6728\n",
      "Balanced Accuracy: 0.4550\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "\n",
    "# Assuming 'red_wine' is your DataFrame and 'quality_label' is the target column\n",
    "X = red_wine.drop(['quality_label', 'quality'], axis=1)\n",
    "y = red_wine['quality_label']\n",
    "\n",
    "# Split your data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Initialize RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "\n",
    "# Apply RandomOverSampler to your training data to balance it\n",
    "X_ros, y_ros = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "# Initialize your model - here, we use GradientBoostingClassifier as an example\n",
    "model = GradientBoostingClassifier(n_estimators=100, random_state=453)\n",
    "\n",
    "# Fit the model on the oversampled training data\n",
    "model.fit(X_ros, y_ros)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "balanced_accuracy = balanced_accuracy_score(y_test, predictions)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Balanced Accuracy: {balanced_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [272, 271]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/pierreloyal/Desktop/Bootcamp CA/Winery Project/ml_red_wine.ipynb Cellule 52\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pierreloyal/Desktop/Bootcamp%20CA/Winery%20Project/ml_red_wine.ipynb#Y102sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m confusion_matrix\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/pierreloyal/Desktop/Bootcamp%20CA/Winery%20Project/ml_red_wine.ipynb#Y102sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m confusion_matrix(y_test, pred)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:317\u001b[0m, in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconfusion_matrix\u001b[39m(\n\u001b[1;32m    233\u001b[0m     y_true, y_pred, \u001b[39m*\u001b[39m, labels\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, normalize\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m\n\u001b[1;32m    234\u001b[0m ):\n\u001b[1;32m    235\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Compute confusion matrix to evaluate the accuracy of a classification.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m \n\u001b[1;32m    237\u001b[0m \u001b[39m    By definition a confusion matrix :math:`C` is such that :math:`C_{i, j}`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[39m    (0, 2, 1, 1)\u001b[39;00m\n\u001b[1;32m    316\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 317\u001b[0m     y_type, y_true, y_pred \u001b[39m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[1;32m    318\u001b[0m     \u001b[39mif\u001b[39;00m y_type \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    319\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m is not supported\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m y_type)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:86\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_targets\u001b[39m(y_true, y_pred):\n\u001b[1;32m     60\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \n\u001b[1;32m     62\u001b[0m \u001b[39m    This converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[39m    y_pred : array or indicator matrix\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 86\u001b[0m     check_consistent_length(y_true, y_pred)\n\u001b[1;32m     87\u001b[0m     type_true \u001b[39m=\u001b[39m type_of_target(y_true, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my_true\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     88\u001b[0m     type_pred \u001b[39m=\u001b[39m type_of_target(y_pred, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my_pred\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:397\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    395\u001b[0m uniques \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(lengths)\n\u001b[1;32m    396\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(uniques) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 397\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    398\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    399\u001b[0m         \u001b[39m%\u001b[39m [\u001b[39mint\u001b[39m(l) \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m lengths]\n\u001b[1;32m    400\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [272, 271]"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        high       0.00      0.00      0.00         3\n",
      "         low       0.69      0.82      0.75       128\n",
      "      medium       0.77      0.62      0.69       141\n",
      "\n",
      "    accuracy                           0.71       272\n",
      "   macro avg       0.49      0.48      0.48       272\n",
      "weighted avg       0.72      0.71      0.71       272\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pred, target_names=[\"high\",\"low\",\"medium\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
